---
title: Home
description: "A personal website of Yang Yongyi."
---

<style>
#_end ~ * {
	display: none;
}
</style>

<img src="/images/partywizard.gif" style="display:inline-block;">

# Yongyi Yang (杨永祎)

Yongyi is a fourth-year Ph.D. student at the University of Michigan, advised by [Prof. Wei Hu](http://weihu.me/). He is an intern in the [NTT Research PAI Group](https://ntt-research.com/pai-group/) at Harvard University, as part of the Harvard CBS-NTT program, under the advisement of [Dr. Hidenori Tanaka](https://sites.google.com/view/htanaka/home). His research focuses on understanding the foundations and principles of deep learning, spanning research areas such as deep learning theory, science of deep learning, and mechanistic interpretability. Besides, he is also broadly interested in many other research topics of broad interest within AI and theory, including efficient implementation of AI algorithms and learning on graphs.

Yongyi received his Bachelor of Science from Fudan university, under the supervision of [Prof. Xipeng Qiu](https://xpqiu.github.io/). He also had an internship at [Amazon Shanghai AI Lab](https://www.amazonaws.cn/en/ailab/ "this website is too ugly...") and has his fortune to be advised by [Dr. David Wipf](http://www.davidwipf.com/) and [Prof. Zengfeng Huang](https://zengfenghuang.github.io/).

Besides academic research, Yongyi also harbors a passion in mathematics, Chinese classical literature and [XiaoXue](https://zh.wikipedia.org/wiki/%E5%B0%8F%E5%AD%B8_(%E7%B6%93%E5%AD%B8)). Feel free to contact if you share the same interests.

## Contact & Other info
+ E-mail: yongyi at umich dot edu
+ GitHub: [FFTYYY](https://github.com/FFTYYY)
+ WeChat: [yyyern](/images/wechat.jpg)
+ Google Scholar: [Yongyi Yang](https://scholar.google.com/citations?user=EmL0jD0AAAAJ&h)

## Miscellaneous

+ I recently published an npm package [mouseless](https://github.com/FFTYYY/mouseless), that helps to define high-level keyboard interactions in UI development.

+ I've added a page to collect some problems I've encountered during my research that I haven't yet solved. See [Problems](/post/problems/). If you have any insights on (or just want to discuss about) any of them, I would greatly appreciate hearing from you.

## Publications and Manuscript

+  [SNIP: An Adaptive Mixed Precision Framework for Subbyte Large Language Model Training](https://www.arxiv.org/abs/2602.01410)
	*Yunjie Pan, __Yongyi Yang__, Hanmei Yang, Scott Mahlke*
	
	ASPLOS 2026


+  [mHC-lite: You Don't Need 20 Sinkhorn-Knopp Iterations](https://arxiv.org/abs/2601.05732)
	*__Yongyi Yang__\*, Jianyang Gao\**

	arxiv preprint

+  [An Equivariance Toolbox for Learning Dynamics](https://arxiv.org/abs/2512.21447)
	*__Yongyi Yang__, Liu Ziyin*

	arxiv preprint

+  [Topological Invariance and Breakdown in Learning](https://arxiv.org/abs/2510.02670)
    *__Yongyi Yang__, Tomaso Poggio, Isaac Chuang, Liu Ziyin*

	arxiv preprint

+  [Provable Low-Frequency Bias of In-Context Learning of Representations](https://arxiv.org/abs/2507.13540)
    *__Yongyi Yang__, Hidenori Tanaka, Wei Hu*

	arxiv preprint

+  [New Evidence of the Two-Phase Learning Dynamics of Neural Networks](https://arxiv.org/abs/2505.13900)
	*Zhanpeng Zhou, __Yongyi Yang__, Mahito Sugiyama, Junchi Yan*

	arxiv preprint

+  [RaanA: A Fast, Flexible, and Data-Efficient Post-Training Quantization Algorithm](https://arxiv.org/abs/2504.03717)
	*__Yongyi Yang__, Jianyang Gao, Wei Hu*

	arxiv preprint

+  [ICLR: In-Context Learning of Representations](https://arxiv.org/abs/2501.00070)
	*Core Francisco Park\*, Andrew Lee\*, Ekdeep Singh Lubana\*, __Yongyi Yang__\*, Maya Okawa, Kento Nishi, Martin Wattenberg, Hidenori Tanaka*

	ICLR 2025



+  [Swing-by Dynamics in Concept Learning and Compositional Generalization](https://arxiv.org/abs/2410.08309)
	*__Yongyi Yang__, Core Francisco Park, Ekdeep Singh Lubana, Maya Okawa, Wei Hu, Hidenori Tanaka*

	ICLR 2025

+  [Practical and Asymptotically Optimal Quantization of High-Dimensional Vectors in Euclidean Space for Approximate Nearest Neighbor Search](https://arxiv.org/abs/2409.09913)
	*Jianyang Gao, Yutong Gou, Yuexuan Xu, __Yongyi Yang__, Cheng Long, Raymond Chi-Wing Wong*


	SIGMOD 2025

	arXiv preprint arXiv:2409.09913 (September, 2024)


+   [HERTA: A High-Efficiency and Rigorous Training Algorithm for Unfolded Graph Neural Networks](https://arxiv.org/abs/2403.18142)
	*__Yongyi Yang__, Jiaming Yang, Wei Hu, Michał Dereziński*

	arxiv preprint

+   [Going Beyond Linear Mode Connectivity: The Layerwise Linear Feature Connectivity](https://arxiv.org/abs/2307.08286)
	*Zhanpeng Zhou, __Yongyi Yang__, Xiaojiang Yang, Junchi Yan, Wei Hu*

	Neurips 2023

+   [Are Neurons Actually Collapsed? On the Fine-Grained Structure in Neural Representations](https://arxiv.org/abs/2306.17105)
	*__Yongyi Yang__, Jacob Steinhardt, Wei Hu*

	ICML 2023


+   [Descent Steps of a Relation-Aware Energy Produce Heterogeneous Graph Neural Networks](https://arxiv.org/abs/2206.11081)
	*Hongjoon Ahn,__Yongyi Yang__, Quan Gan, David Wipf, Taesup Moon*

	Neurips 2022

+	[Transformers from an Optimization Perspective](https://arxiv.org/abs/2205.13891)
	*__Yongyi Yang__, Zengfeng Huang, David Wipf*

	Neurips 2022

+	[Why Propagate Alone? Parallel Use of Labels and Features on Graphs](https://arxiv.org/abs/2110.07190)
	*Yangkun Wang, Jiarui Jin, Weinan Zhang, __Yongyi Yang__, Jiuhai Chen, Quan Gan, Yong Yu, Zheng Zhang, Zengfeng Huang, David Wipf*

	ICLR 2022

+	[Graph Neural Networks Inspired by Classical Iterative Algorithms](https://arxiv.org/abs/2103.06064)
	*__Yongyi Yang__ , Tang Liu, Yangkun Wang, Jinjing Zhou, Quan Gan, Zhewei Wei, Zheng Zhang, Zengfeng Huang, David Wipf*

	ICML 2021, long talk

+	[Implicit vs Unfolded Graph Neural Networks](https://arxiv.org/abs/2111.06592)
	*__Yongyi Yang__, Yangkun Wang, Tang Liu, Zengfeng Huang, David Wipf*

	JMLR vol. 26, 2025 

	arXiv preprint arXiv:2111.06592 (2021)

+	[Relation of the Relations: A New Paradigm of the Relation Extraction Problem](https://arxiv.org/abs/2006.03719)
	*Zhijing Jin\*, __Yongyi Yang\*__, Xipeng Qiu, Zheng Zhang*

	arxiv preprint 


## Community Service
 - Conference reviewer @ ICML (2023, 2024, 2025), NeurIPS (2023, 2024, 2025), ICLR (2023, 2024, 2025, 2026).
 - Workshop reviewer @ ICBINB (2023), W3L (2023).
 - Journal reviewer @ IEEE TKDE , IEEE TSP, IEEE TNNLS, IEEE TPAMI.

(Last update: 02/06/2026)

<div id="_end"></div>