<!DOCTYPE html>
<html lang="en-us">
  <head>
	<meta name="generator" content="Hugo 0.110.0">

    <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
    <link rel="manifest" href="/images/site.webmanifest">

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="A personal website of Yang Yongyi.">
    <title>Home | Yongyi Yang</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    <link rel="stylesheet" href="/css/theme-override.css">
    <header>

  <nav>
    <ul>
      
      
      <li class="pull-left current">
        <a href="/">~/yongyi yang</a>
      </li>
      
      
      <li class="pull-left ">
        <a href="/post/problems/">~/problems</a>
      </li>
      

      

    </ul>
  </nav>
</header>

  </head>

  <body>
    <br/>


<div class="content-wrapper">


  <style>
#_end ~ * {
	display: none;
}
</style>
<img src="/images/partywizard.gif" style="display:inline-block;">
<h1 id="yongyi-yang-杨永祎">Yongyi Yang (杨永祎)</h1>
<p>Yongyi is a fourth-year Ph.D. student at the University of Michigan, advised by <a href="http://weihu.me/">Prof. Wei Hu</a>. He is currently doing an internship at <a href="https://ntt-research.com/pai-group/">NTT Research PAI Group</a> under the advisement of <a href="https://sites.google.com/view/htanaka/home">Dr. Hidenori Tanaka</a>. His research focuses on understanding the foundations and principles of deep learning, spanning research areas such as deep learning theory, science of deep learning, and mechanistic interpretability. Besides, he is also broadly interested in many other research topics of broad interest within AI, including large language model quantization and graph neural networks.</p>
<p>Yongyi received his Bachelor of Science from Fudan university, under the supervision of <a href="https://xpqiu.github.io/">Prof. Xipeng Qiu</a>. He also had an internship at <a href="https://www.amazonaws.cn/en/ailab/" title="this website is too ugly...">Amazon Shanghai AI Lab</a> and has his fortune to be advised by <a href="http://www.davidwipf.com/">Dr. David Wipf</a> and <a href="https://zengfenghuang.github.io/">Prof. Zengfeng Huang</a>.</p>
<p>Besides academic research, Yongyi also harbors a passion in mathematics, Chinese classical literature and <a href="https://zh.wikipedia.org/wiki/%E5%B0%8F%E5%AD%B8_(%E7%B6%93%E5%AD%B8)">XiaoXue</a>. Feel free to contact if you share the same interests.</p>
<h2 id="contact--other-info">Contact &amp; Other info</h2>
<ul>
<li>E-mail: yongyi at umich dot edu</li>
<li>GitHub: <a href="https://github.com/FFTYYY">FFTYYY</a></li>
<li>WeChat: <a href="/images/wechat.jpg">yyyern</a></li>
<li>Google Scholar: <a href="https://scholar.google.com/citations?user=EmL0jD0AAAAJ&amp;h">Yongyi Yang</a></li>
</ul>
<h2 id="miscellaneous">Miscellaneous</h2>
<ul>
<li>
<p>I recently published an npm package <a href="https://github.com/FFTYYY/mouseless">mouseless</a>, that helps to define high-level keyboard interactions in UI development.</p>
</li>
<li>
<p>I&rsquo;ve added a page to collect some problems I&rsquo;ve encountered during my research that I haven&rsquo;t yet solved. See <a href="/post/problems/">Problems</a>. If you have any insights on (or just want to discuss about) any of them, I would greatly appreciate hearing from you.</p>
</li>
</ul>
<h2 id="publications-and-manuscripts">Publications and Manuscripts</h2>
<ul>
<li>
<p><a href="https://arxiv.org/abs/2510.02670">Topological Invariance and Breakdown in Learning</a>
<em><strong>Yongyi Yang</strong>, Tomaso Poggio, Isaac Chuang, Liu Ziyin</em></p>
<p>arxiv preprint</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/2507.13540">Provable Low-Frequency Bias of In-Context Learning of Representations</a>
<em><strong>Yongyi Yang</strong>, Hidenori Tanaka, Wei Hu</em></p>
<p>arxiv preprint</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/2505.13900">New Evidence of the Two-Phase Learning Dynamics of Neural Networks</a>
<em>Zhanpeng Zhou, <strong>Yongyi Yang</strong>, Mahito Sugiyama, Junchi Yan</em></p>
<p>arxiv preprint</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/2504.03717">RaanA: A Fast, Flexible, and Data-Efficient Post-Training Quantization Algorithm</a>
<em><strong>Yongyi Yang</strong>, Jianyang Gao, Wei Hu</em></p>
<p>arxiv preprint</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/2501.00070">ICLR: In-Context Learning of Representations</a>
<em>Core Francisco Park*, Andrew Lee*, Ekdeep Singh Lubana*, <strong>Yongyi Yang</strong>*, Maya Okawa, Kento Nishi, Martin Wattenberg, Hidenori Tanaka</em></p>
<p>ICLR 2025</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/2410.08309">Swing-by Dynamics in Concept Learning and Compositional Generalization</a>
<em><strong>Yongyi Yang</strong>, Core Francisco Park, Ekdeep Singh Lubana, Maya Okawa, Wei Hu, Hidenori Tanaka</em></p>
<p>ICLR 2025</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/2409.09913">Practical and Asymptotically Optimal Quantization of High-Dimensional Vectors in Euclidean Space for Approximate Nearest Neighbor Search</a>
<em>Jianyang Gao, Yutong Gou, Yuexuan Xu, <strong>Yongyi Yang</strong>, Cheng Long, Raymond Chi-Wing Wong</em></p>
<p>SIGMOD 2025</p>
<p>arXiv preprint arXiv:2409.09913 (September, 2024)</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/2403.18142">HERTA: A High-Efficiency and Rigorous Training Algorithm for Unfolded Graph Neural Networks</a>
<em><strong>Yongyi Yang</strong>, Jiaming Yang, Wei Hu, Michał Dereziński</em></p>
<p>arxiv preprint</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/2307.08286">Going Beyond Linear Mode Connectivity: The Layerwise Linear Feature Connectivity</a>
<em>Zhanpeng Zhou, <strong>Yongyi Yang</strong>, Xiaojiang Yang, Junchi Yan, Wei Hu</em></p>
<p>Neurips 2023</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/2306.17105">Are Neurons Actually Collapsed? On the Fine-Grained Structure in Neural Representations</a>
<em><strong>Yongyi Yang</strong>, Jacob Steinhardt, Wei Hu</em></p>
<p>ICML 2023</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/2206.11081">Descent Steps of a Relation-Aware Energy Produce Heterogeneous Graph Neural Networks</a>
<em>Hongjoon Ahn,<strong>Yongyi Yang</strong>, Quan Gan, David Wipf, Taesup Moon</em></p>
<p>Neurips 2022</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/2205.13891">Transformers from an Optimization Perspective</a>
<em><strong>Yongyi Yang</strong>, Zengfeng Huang, David Wipf</em></p>
<p>Neurips 2022</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/2110.07190">Why Propagate Alone? Parallel Use of Labels and Features on Graphs</a>
<em>Yangkun Wang, Jiarui Jin, Weinan Zhang, <strong>Yongyi Yang</strong>, Jiuhai Chen, Quan Gan, Yong Yu, Zheng Zhang, Zengfeng Huang, David Wipf</em></p>
<p>ICLR 2022</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/2103.06064">Graph Neural Networks Inspired by Classical Iterative Algorithms</a>
<em><strong>Yongyi Yang</strong> , Tang Liu, Yangkun Wang, Jinjing Zhou, Quan Gan, Zhewei Wei, Zheng Zhang, Zengfeng Huang, David Wipf</em></p>
<p>ICML 2021, long talk</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/2111.06592">Implicit vs Unfolded Graph Neural Networks</a>
<em><strong>Yongyi Yang</strong>, Yangkun Wang, Tang Liu, Zengfeng Huang, David Wipf</em></p>
<p>JMLR vol. 26, 2025</p>
<p>arXiv preprint arXiv:2111.06592 (2021)</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/2006.03719">Relation of the Relations: A New Paradigm of the Relation Extraction Problem</a>
<em>Zhijing Jin*, <strong>Yongyi Yang*</strong>, Xipeng Qiu, Zheng Zhang</em></p>
<p>arxiv preprint</p>
</li>
</ul>
<h2 id="community-service">Community Service</h2>
<ul>
<li>Conference reviewer @ ICML (2023, 2024, 2025), Neurips (2023, 2024, 2025), ICLR (2023, 2024, 2025, 2026).</li>
<li>Workshop reviewer @ ICBINB (2023), W3L (2023).</li>
<li>Journal reviewer @ IEEE TKDE , IEEE TSP, IEEE TNNLS, IEEE TPAMI.</li>
</ul>
<p>(Last update: 10/05/2025)</p>
<div id="_end"></div>

  <ul>
     
     
     
     <li>
       <span class="date">0001/01/01</span>
       <a href="/post/problems/">Problems</a>
     </li>
     
   </ul>
</div>
    <footer>
      
<script>
(function() {
  function center_el(tagName) {
    var tags = document.getElementsByTagName(tagName), i, tag;
    for (i = 0; i < tags.length; i++) {
      tag = tags[i];
      var parent = tag.parentElement;
      
      if (parent.childNodes.length === 1) {
        
        if (parent.nodeName === 'A') {
          parent = parent.parentElement;
          if (parent.childNodes.length != 1) continue;
        }
        if (parent.nodeName === 'P') parent.style.textAlign = 'center';
      }
    }
  }
  var tagNames = ['img', 'embed', 'object'];
  for (var i = 0; i < tagNames.length; i++) {
    center_el(tagNames[i]);
  }
})();
</script>

      
      <hr/>
      Theme: Hugo-Classic | <a href="https://github.com/goodroot/hugo-classic">Github</a>
      
    </footer>
  </body>
</html>

